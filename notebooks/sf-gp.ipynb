{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Utility Functions\n",
    "'''\n",
    "# DATA: months since 2012, X coord, Y coord\n",
    "# if split size = 0, do non\n",
    "def split(X, tr_size):\n",
    "    n_col = np.shape(X)[1]\n",
    "    if tr_size != 0:\n",
    "        Y = np.copy(X)\n",
    "        np.random.shuffle(Y)\n",
    "        break_pt = tr_size * np.shape(X)[0]\n",
    "        train, test = Y[:break_pt,:], Y[break_pt:,:]\n",
    "    else:\n",
    "        break_pt = (3500./4400.) * np.shape(X)[0]\n",
    "        train, test = X[:break_pt,:], X[break_pt:,:]\n",
    "\n",
    "    tr_t, te_t = train[:,n_col-1], test[:,n_col-1]\n",
    "    tr, te = train[:,range(n_col-1)], test[:,range(n_col-1)]\n",
    "    return tr, tr_t, te, te_t\n",
    "\n",
    "# implementation notes: set NaN to mean\n",
    "def normalize_features(X_train):\n",
    "    mean_X_train = np.nanmean(X_train, 0)\n",
    "    for i in xrange(np.shape(X_train)[1]):\n",
    "        col = X_train[:,i]\n",
    "        col[ np.isnan(col) ] = mean_X_train[i]\n",
    "    std_X_train = np.std(X_train, 0)\n",
    "    std_X_train[ std_X_train == 0 ] = 1\n",
    "    X_train_normalized = (X_train - mean_X_train) / std_X_train\n",
    "    return X_train_normalized\n",
    "\n",
    "# Note: bucket edits in place\n",
    "def bucket(X, cols, num_buckets):\n",
    "    Y = np.copy(X)\n",
    "    for col in cols:\n",
    "        buckets = np.linspace(np.min(X[:,col]), np.max(X[:,col]), num=num_buckets+1)\n",
    "        for i in xrange(num_buckets):\n",
    "            X_col = Y[:,col]\n",
    "            X_col[ (buckets[i] <= X_col) & (X_col <= buckets[i+1])] = i\n",
    "            Y[:,col] = X_col\n",
    "    return Y\n",
    "\n",
    "def rmse(predict, true):\n",
    "    return np.sqrt(1.0/np.shape(predict)[0] * np.sum(np.square(predict - true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataMatrix(data):\n",
    "    '''\n",
    "    Transforms a panda dataframe into latitude longitude time period matrix\n",
    "    record of crimes.\n",
    "    '''\n",
    "    X = np.zeros((len(data), 3))\n",
    "    X[:, 1] = data.Latitude.values.astype(float)\n",
    "    X[:, 2] = data.Longitude.values.astype(float)\n",
    "    X[:, 0] = data.TimeFeature.values.astype(int)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Read in data\n",
    "'''\n",
    "# Let's make a plot for some values of N to see if the data works out...\n",
    "sfdata_file = '../../cs281_data/large_data/sfclean.pk'\n",
    "with open(sfdata_file) as fp:\n",
    "    data = pickle.load(fp)\n",
    "    # For sfdata, need to remove outliers\n",
    "    data = data[-120 > data.Longitude][data.Longitude > (-130)]\n",
    "    data = data[data.Latitude > 37][data.Latitude < 40]\n",
    "    \n",
    "good_data = createDataMatrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1834080"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Count data for each cell. If logSpace is true, returns log values.\n",
    "'''\n",
    "def createBuckets(n_buckets = 15, logSpace = True):\n",
    "    data_b = bucket(good_data, [1, 2], n_buckets)\n",
    "\n",
    "    n_time = int(data_b[np.argmax(data_b[:,0])][0])\n",
    "\n",
    "    # buckets = np.zeros((n_time, n_buckets, n_buckets))\n",
    "    buckets2 = np.zeros((n_buckets * n_buckets * n_time, 4))\n",
    "\n",
    "    # divide the data up by year and month\n",
    "    for i in xrange(n_time):\n",
    "        for j in xrange(n_buckets):\n",
    "            for k in xrange(n_buckets):\n",
    "                count = data_b[ (data_b[:,0] == i+1) & \n",
    "                                (data_b[:,1] == j) & \n",
    "                                (data_b[:,2] == k)]\n",
    "                # buckets[i][j][k] = np.size(count,0)\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][0] = i\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][1] = j\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][2] = k\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][3] = np.size(count,0)\n",
    "    print np.shape(buckets2)\n",
    "    \n",
    "    if logSpace:\n",
    "        buckets2[:,3] = np.log(np.add(sys.float_info.epsilon, buckets2[:,3]))\n",
    "    \n",
    "    return buckets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Our GP\n",
    "    other implementations:\n",
    "    - scikit-learn\n",
    "    - GPy\n",
    "'''\n",
    "\n",
    "# compute the kernel matrix\n",
    "# use square exponential by default\n",
    "def ker_se(x, y, l, horz = 1.0):\n",
    "    \n",
    "    n = np.shape(x)[0]\n",
    "    m = np.shape(y)[0]\n",
    "    \n",
    "    t = np.reshape(x, (np.shape(x)[0], 1, np.shape(x)[1]))\n",
    "    s = np.reshape(y, (1, np.shape(y)[0], np.shape(y)[1]))\n",
    "\n",
    "    # tile across columns\n",
    "    cols = np.tile(t, (1, m, 1))\n",
    "    # tile across rows\n",
    "    rows = np.tile(s, (n, 1, 1))\n",
    "    # get the differences and vectorize\n",
    "    diff_vec = np.reshape(cols - rows, (n*m, np.shape(t)[2]))\n",
    "    \n",
    "    M = np.diag(l)\n",
    "    \n",
    "    # use multiply and sum to calculate matrix product\n",
    "    s = np.multiply(-.5, np.sum(np.multiply(diff_vec, np.transpose(np.dot(M, np.transpose(diff_vec)))), axis=1))\n",
    "    se = np.reshape(np.multiply(horz, np.exp(s)), (n, m))\n",
    "    \n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate kernels\n",
    "'''\n",
    "def GaussianProcess(train, train_t, test, test_t, l,\n",
    "                    horz, sig_eps, predict=True, rmse=True, ker='se'):\n",
    "    # Try to be memory efficient by deleting data after use!\n",
    "    if ker == 'se':\n",
    "        ker_fun = ker_se\n",
    "    else:\n",
    "        raise Exception(\"Kernal {} Not Supported!\".format(ker))\n",
    "        \n",
    "    ker1 = ker_fun(train, train, l, horz)\n",
    "    L = np.linalg.cholesky(ker1 + np.multiply(sig_eps, np.identity(np.shape(ker1)[0])))\n",
    "    \n",
    "    alpha = np.linalg.solve(L.T, np.linalg.solve(L, train_t))\n",
    "    \n",
    "    # Only do this if we request the predictions or rmse\n",
    "    ret = []\n",
    "    if predict or rmse:\n",
    "        ker2 = ker_fun(train,test, l, horz)\n",
    "        preds = np.dot(np.transpose(ker2), alpha)\n",
    "        del ker2\n",
    "        ret.append(preds)\n",
    "        \n",
    "    \n",
    "    # Only if we request the rmse\n",
    "    if rmse:\n",
    "        npreds = preds / float(preds.sum())\n",
    "        ntest_t = test_t / float(test_t.sum())\n",
    "        rmse_val = np.sqrt(np.sum(np.square(npreds - ntest_t))/np.shape(preds)[0])\n",
    "        print rmse\n",
    "        ret.append(rmse_val)\n",
    "        \n",
    "    # Calculate the marginal likelihood\n",
    "    likelihood = -.5 * np.dot(np.transpose(train_t), alpha) - np.sum(np.log(np.diagonal(L))) - np.shape(ker1)[0]/2 * np.log(2*np.pi)\n",
    "    ret.append(likelihood)\n",
    "    \n",
    "    del alpha\n",
    "    del L\n",
    "    del ker1\n",
    "    \n",
    "    return tuple(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = { 't' : 0, 'x' : 1, 'y' : 2, 'count' : 3}\n",
    "def createHeatMap(X):\n",
    "    '''\n",
    "    Given a data set, creates a heatmap of it based on x,y coordinates.\n",
    "    Ignore the temporal feature. You should subset the data before passing\n",
    "    it into this function if you'd like a heatmap for a specific time period.\n",
    "    '''\n",
    "    n = X[:, columns['x']].astype(int).max()\n",
    "    m = X[:, columns['y']].astype(int).max()\n",
    "    heatmap = np.zeros((n,m))\n",
    "    for i in xrange(n):\n",
    "        for j in xrange(m):\n",
    "            total = X[(X[:, columns['x']] == i) & \n",
    "                      (X[:, columns['y']] == j), columns['count']].sum()\n",
    "            if total > 0:\n",
    "                heatmap[i,j] = total\n",
    "    heatmap = heatmap / float(heatmap.sum())\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make some plots for n = 15 for GP process\n",
    "def plotDistribution(predict, true, city, n, process='GP'):\n",
    "    minValue = min(len(predict), 100)\n",
    "    yPred = predict[-minValue:]\n",
    "    yTrue = true[-minValue:]\n",
    "    yPred = yPred / float(np.sum(yPred))\n",
    "    yTrue = yTrue / float(np.sum(yTrue))\n",
    "    plt.clf()\n",
    "    plt.plot(yPred, label=\"Predictions\")\n",
    "    plt.plot(yTrue, label=\"Actual Data\")\n",
    "    plt.title('Predictive Distribution for {}'.format(process))\n",
    "    plt.xlabel('Compressed Features')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.legend()\n",
    "    plt.savefig('../figures/{}_results/{}_n={}_periods={}.png'.format(\n",
    "        city, process, n,12))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotHeatMaps(X_test, predict, city, n, process='GP'):\n",
    "    # Attach the predictions to the data\n",
    "    trueValues = np.copy(X_test)\n",
    "    predictedValues = np.copy(X_test)\n",
    "    predictedValues[:, columns['count']] = predict\n",
    "\n",
    "    # Now we want to plot the heatmaps for the predictions/actual data\n",
    "    # by time period\n",
    "    months = np.unique(X_test[:, columns['t']])\n",
    "    for month in months:\n",
    "        # Create the heatmaps \n",
    "        selected = (X_test[:, columns['t']] == month)\n",
    "        if selected.sum() > 0:\n",
    "            plt.clf()\n",
    "            m = createHeatMap(trueValues[selected, :])\n",
    "            if m.sum() > 0:\n",
    "                sns.heatmap(m)\n",
    "                plt.title('True Density Distribution in Month {}'.format(month))\n",
    "                plt.savefig('../figures/{}_results/{}_heatmap_true_n={}_t={}.png'.format(\n",
    "                    city, process, n, month))\n",
    "                plt.close()\n",
    "\n",
    "            plt.clf()\n",
    "            m = createHeatMap(predictedValues[selected, :])\n",
    "            if m.sum() > 0:\n",
    "                sns.heatmap(m)\n",
    "                plt.title('Predicted Density Distribution in Month {}'.format(month))\n",
    "                plt.savefig('../figures/{}_results/{}_heatmap_pred_n={}_t={}.png'.format(\n",
    "                    city, process, n, month))\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3850, 4)\n",
      "CPU times: user 1min 21s, sys: 0 ns, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "log = False\n",
    "%time data = createBuckets(n_buckets=5,logSpace=log)  # default is 15, logSpace=True\n",
    "# %time train, train_t, test, test_t = split(data, 0)\n",
    "#l = np.ones(3)\n",
    "#horz = 1.0\n",
    "#sig_eps = 1.0\n",
    "\n",
    "#%time predictions, rmse, likelihood = GaussianProcess(train, train_t, test, test_t, l, horz, sig_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only do the below if logspace !\n",
    "if log:\n",
    "    test_t = np.exp(test_t)\n",
    "    predictions = np.exp(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotDistribution(predictions, test_t, 'sf', 5, process='GPSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros((test.shape[0], test.shape[1] + 1)).astype(int)\n",
    "X_test[:,:-1] = test\n",
    "X_test[:,-1] = test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotHeatMaps(X_test, predictions, 'sf', 5, process='GPSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Easier method for calling our GP model! Kernal defaults to SE.\n",
    "'''\n",
    "def optimizeGaussianProcess(n, l1, l2, l3, horz, sig_eps,\n",
    "                            log=False):\n",
    "    # Bucketize the data as specified! By default, does Boston data.\n",
    "    data = createBuckets(n, logSpace=log)\n",
    "    \n",
    "    # Split for latest year.\n",
    "    train, train_t, test, test_t = split(data, 0)\n",
    "    \n",
    "    # Calculate the likelihood\n",
    "    l = np.array([l1,l2,l3])\n",
    "    likelihood = GaussianProcess(train, train_t, test, test_t,\n",
    "                                 l, horz, sig_eps,\n",
    "                                 predict = False, rmse = False)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect likelihoods for different n values\n",
    "testN = range(2,10) + range(10,20,5)\n",
    "likelihoods = []\n",
    "for n in testN:\n",
    "    likelihood = optimizeGaussianProcess(n, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
    "                                        log=False)\n",
    "    likelihoods.append(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = testN\n",
    "y = likelihoods\n",
    "line1 = plt.plot(x, y, label=\"Log Likelihood\")\n",
    "plt.title('GP Predictions for Boston')\n",
    "plt.xlabel('Dimension of Grid')\n",
    "plt.ylabel('Log Likelihood')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Smart GP\n",
    "'''\n",
    "\n",
    "import GPy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time data = createBuckets(n_buckets=10, logSpace=log)  # default is 15, logSpace=True\n",
    "%time train, train_t, test, test_t = split(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_t = train_t.reshape((train_t.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kern = gp.kern.RBF(input_dim=3, variance=1., lengthscale=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b9bdb0df20f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time m = gp.models.GPRegression(train, train_t, kern)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2334\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2335\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2336\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2338\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2255\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2256\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2257\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2258\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/GPy/core/parameterization/parameterized.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kw)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_highest_parent_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connect_fixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"calling parameters changed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/GPy/core/gp.pyc\u001b[0m in \u001b[0;36mparameters_changed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0myourself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0munexpected\u001b[0m \u001b[0mconsequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_marginal_likelihood\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_method\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dL_dthetaL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_gradients_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dL_dK'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/GPy/inference/latent_function_inference/exact_gaussian_inference.pyc\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, kern, X, likelihood, Y, mean_function, Y_metadata)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mKy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mdiag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_variance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mWi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLWi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_logdet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdpotrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYYT_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/GPy/util/linalg.pyc\u001b[0m in \u001b[0;36mpdinv\u001b[1;34m(A, *args)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mlogdet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[0mLi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtrtri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mAi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdpotri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[1;31m# Ai = np.tril(Ai) + np.tril(Ai,-1).T\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0msymmetrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/GPy/util/linalg.pyc\u001b[0m in \u001b[0;36mdpotri\u001b[1;34m(A, lower)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforce_F_ordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlapack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpotri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#needs to be zero here, seems to be a scipy bug\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0msymmetrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time m = gp.models.GPRegression(train, train_t, kern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
